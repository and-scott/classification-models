{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "Specifically, the professor says \"I need to prove that left-handedness is caused by some personality trait. Go find that personality trait and the data to back it up.\"\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### 1. In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> Check out the codebook in the repo for some inspiration.\n",
    "\n",
    "> You'll be asked to answer one of these questions later on, so make sure your questions are based on the data provided (specifically Q1 - Q44)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: What question is most highly correlated with left handedness?\n",
    "        Is there a relationship between handedness and risk taking behaviors?\n",
    "        As peoples affinity for guns increases, how does their average handedness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 2. Read in the file titled \"data.csv.\"\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!\n",
    "\n",
    "> Notice that the data is separated by *tabs* (not commas, like most .csv files). Check out the parameters to see if there is anything that might help you parse this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  country  fromgoogle  engnat  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1  ...       US           2       1   \n",
       "1   1   5   1   4   2   5   5   4   1    5  ...       CA           2       1   \n",
       "2   1   2   1   1   5   4   3   2   1    4  ...       NL           2       2   \n",
       "3   1   4   1   5   1   4   5   4   3    5  ...       US           2       1   \n",
       "4   5   1   5   1   5   1   5   1   3    1  ...       US           2       1   \n",
       "\n",
       "   age  education  gender  orientation  race  religion  hand  \n",
       "0   22          3       1            1     3         2     3  \n",
       "1   14          1       2            2     6         1     1  \n",
       "2   30          4       1            1     1         1     2  \n",
       "3   18          2       2            5     3         2     2  \n",
       "4   22          3       1            1     3         2     3  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suppose that, instead of us giving you this data in a file, you were actually conducting a survey to gather this data yourself. From an ethics/privacy point of view, what are three things you might consider when attempting to gather this data?\n",
    "> When working with sensitive data like sexual orientation or gender identity, we need to consider how this data could be used if it fell into the wrong hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Make any sensitive question voluntary that is not necessarily germane.\n",
    "        In the event we do feel it ncessary to include sensitive data, there should be no personally identifying information bundled with that data.\n",
    "        Being actuely aware of potential conflicts and making our data gathering as inclusive as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 4. Conduct exploratory data analysis on this dataset.\n",
    "> If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  country  fromgoogle  \\\n",
       "0      4   1   5   1   5   1   5   1   4    1  ...       US           2   \n",
       "1      1   5   1   4   2   5   5   4   1    5  ...       CA           2   \n",
       "2      1   2   1   1   5   4   3   2   1    4  ...       NL           2   \n",
       "3      1   4   1   5   1   4   5   4   3    5  ...       US           2   \n",
       "4      5   1   5   1   5   1   5   1   3    1  ...       US           2   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...      ...         ...   \n",
       "4179   3   5   4   5   2   4   2   2   2    5  ...       US           1   \n",
       "4180   1   5   1   5   1   4   2   4   1    4  ...       US           1   \n",
       "4181   3   2   2   4   5   4   5   2   2    5  ...       PL           2   \n",
       "4182   1   3   4   5   1   3   3   1   1    3  ...       US           2   \n",
       "4183   2   5   3   3   5   3   4   3   1    5  ...       NZ           2   \n",
       "\n",
       "      engnat  age  education  gender  orientation  race  religion  hand  \n",
       "0          1   22          3       1            1     3         2     3  \n",
       "1          1   14          1       2            2     6         1     1  \n",
       "2          2   30          4       1            1     1         1     2  \n",
       "3          1   18          2       2            5     3         2     2  \n",
       "4          1   22          3       1            1     3         2     3  \n",
       "...      ...  ...        ...     ...          ...   ...       ...   ...  \n",
       "4179       1   18          2       1            1     6         2     1  \n",
       "4180       1   18          2       2            1     3         2     1  \n",
       "4181       2   22          2       1            1     6         1     1  \n",
       "4182       1   16          1       2            5     1         1     1  \n",
       "4183       1   22          3       2            4     6         1     1  \n",
       "\n",
       "[4184 rows x 56 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1             0\n",
       "Q2             0\n",
       "Q3             0\n",
       "Q4             0\n",
       "Q5             0\n",
       "Q6             0\n",
       "Q7             0\n",
       "Q8             0\n",
       "Q9             0\n",
       "Q10            0\n",
       "Q11            0\n",
       "Q12            0\n",
       "Q13            0\n",
       "Q14            0\n",
       "Q15            0\n",
       "Q16            0\n",
       "Q17            0\n",
       "Q18            0\n",
       "Q19            0\n",
       "Q20            0\n",
       "Q21            0\n",
       "Q22            0\n",
       "Q23            0\n",
       "Q24            0\n",
       "Q25            0\n",
       "Q26            0\n",
       "Q27            0\n",
       "Q28            0\n",
       "Q29            0\n",
       "Q30            0\n",
       "Q31            0\n",
       "Q32            0\n",
       "Q33            0\n",
       "Q34            0\n",
       "Q35            0\n",
       "Q36            0\n",
       "Q37            0\n",
       "Q38            0\n",
       "Q39            0\n",
       "Q40            0\n",
       "Q41            0\n",
       "Q42            0\n",
       "Q43            0\n",
       "Q44            0\n",
       "introelapse    0\n",
       "testelapse     0\n",
       "country        0\n",
       "fromgoogle     0\n",
       "engnat         0\n",
       "age            0\n",
       "education      0\n",
       "gender         0\n",
       "orientation    0\n",
       "race           0\n",
       "religion       0\n",
       "hand           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 5. Suppose I wanted to use Q1 - Q44 to predict whether or not the person is left-handed. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Classification because handedness is binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed based on their responses to Q1 - Q44. Before doing that, however, you remember that it is often a good idea to standardize your variables. In general, why would we standardize our variables? Give an example of when we would standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Anytime we have variables that are on different scales. THis would create a skew and the nearest nighbor would give more emphasis to the variable on the larger scale. So if we were looking at price of a home based on rooms and based on acreage in sq footage, we would want to standardize that because the acreage would be overwhelming to rooms which would likely be bound somewhere between 1-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Give an example of when we might not standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: When the variables are already on the same scale. So if we were looking at rooms and acreage but acreage this time were actually measured in acres. these numbers would be close enough in scale that one would not be disproportionately influential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Based on your answers to 6 and 7, do you think we should standardize our predictor variables in this case (remember we're only using Q1 - Q44 as predictor variables)? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: No because the scale is 1-5 on those questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed. What munging/cleaning do we need to do to our $y$ variable in order to explicitly answer this question? Do it.\n",
    "\n",
    "> Note: Think critically about how to clean the $y$ variable based on your problem statement.\n",
    "   \n",
    "   > Be sure to provide some explanation/justification for your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Lefthanded will be assigned a 1, and everything else will be assigned a 0 because we are concerned with whether they are lefthanded exclusively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3542\n",
       "2     452\n",
       "3     179\n",
       "0      11\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = [1 if i == 2 else 0 for i in df['hand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3732\n",
       "1     452\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "4179    0\n",
       "4180    0\n",
       "4181    0\n",
       "4182    0\n",
       "4183    0\n",
       "Name: y, Length: 4184, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. The professor for whom you work suggests that you set $k = 4$. In this specific case, why might this be a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Let's *(finally)* use $k$-nearest neighbors to predict whether or not a person is left-handed!\n",
    "\n",
    "> Be sure to create a train/test split with your data!\n",
    "\n",
    "> Create four separate models, one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$.\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [col for col in df if 'Q' in col]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['introelapse', 'testelapse', 'country',\n",
    "       'fromgoogle', 'engnat', 'age', 'education', 'gender', 'orientation',\n",
    "       'race', 'religion', 'hand', 'y'], axis = 1)\n",
    "\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_3 = KNeighborsClassifier(n_neighbors = 3)\n",
    "k_3.fit(X_train, y_train)\n",
    "\n",
    "k_5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "k_5.fit(X_train, y_train)\n",
    "\n",
    "k_15 = KNeighborsClassifier(n_neighbors = 15)\n",
    "k_15.fit(X_train, y_train)\n",
    "\n",
    "k_25 = KNeighborsClassifier(n_neighbors = 25)\n",
    "k_25.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being good data scientists, we know that we might not run just one type of model. We might run many different models and see which is best.\n",
    "\n",
    "### 12. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, let's check the [documentation for logistic regression in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Is there default regularization? If so, what is it? If not, how do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There is default regularization seen in the LogisticRegression parameters of penalty and C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, should we standardize our features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We do not need to standardize because the variables are already on the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Let's use logistic regression to predict whether or not the person is left-handed.\n",
    "\n",
    "\n",
    "> Be sure to use the same train/test split with your data as with your $k$-NN model above!\n",
    "\n",
    "> Create four separate logistic regression models, one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_1 = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'liblinear')\n",
    "lasso_1.fit(X_train, y_train)\n",
    "\n",
    "lasso_10 = LogisticRegression(penalty = 'l1', C = 0.1, solver = 'liblinear')\n",
    "lasso_10.fit(X_train, y_train)\n",
    "\n",
    "ridge_1 = LogisticRegression(penalty = 'l2', C = 1.0, solver = 'liblinear')\n",
    "ridge_1.fit(X_train, y_train)\n",
    "\n",
    "ridge_10 = LogisticRegression(penalty = 'l2', C = 0.1, solver = 'liblinear')\n",
    "ridge_10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate the model(s).\n",
    "\n",
    "### 15. Before calculating any score on your data, take a step back. Think about your $X$ variable and your $Y$ variable. Do you think your $X$ variables will do a good job of predicting your $Y$ variable? Why or why not? What impact do you think this will have on your scores?\n",
    "\n",
    "> For this question, consider your own thoughts (or research) on the relationship between psychological factors and handedness.\n",
    "\n",
    "> When evaluating your models later on, consider whether a high score always means the variables are good predictors. Is this always the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Not really because the variables are pretty broad. Additionally, inuition says that behavioral patterns relationship to handedness is unfounded, old wives' tales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Using accuracy as your metric, evaluate all eight of your models on both the training and testing sets. Put your scores below. (If you want to be fancy and generate a table in Markdown, there's a [Markdown table generator site linked here](https://www.tablesgenerator.com/markdown_tables#).)\n",
    "- Note: Your answers here might look a little weird. You didn't do anything wrong; that's to be expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-nearest neighbors training accuracy with k = 3: 0.9079031230082856\n",
      "k-nearest neighbors testing accuracy with k = 3: 0.8499043977055449\n",
      "k-nearest neighbors training accuracy with k = 5: 0.9018483110261313\n",
      "k-nearest neighbors testing accuracy with k = 5: 0.869980879541109\n",
      "k-nearest neighbors training accuracy with k = 15: 0.897068196303378\n",
      "k-nearest neighbors testing accuracy with k = 15: 0.8766730401529637\n",
      "k-nearest neighbors training accuracy with k = 25: 0.897068196303378\n",
      "k-nearest neighbors testing accuracy with k = 25: 0.8766730401529637\n",
      "logistic regression training accuracy with LASSO penalty, alpha = 1: 0.897068196303378\n",
      "logistic regression testing accuracy with LASSO penalty, alpha = 1: 0.8766730401529637\n",
      "logistic regression training accuracy with LASSO penalty, alpha = 10: 0.897068196303378\n",
      "logistic regression testing accuracy with LASSO penalty, alpha = 10: 0.8776290630975143\n",
      "logistic regression training accuracy with Ridge penalty, alpha = 1: 0.897068196303378\n",
      "logistic regression testing accuracy with Ridge penalty, alpha = 1: 0.8766730401529637\n",
      "logistic regression training accuracy with Ridge penalty, alpha = 10: 0.897068196303378\n",
      "logistic regression testing accuracy with Ridge penalty, alpha = 10: 0.8776290630975143\n"
     ]
    }
   ],
   "source": [
    "print(\"k-nearest neighbors training accuracy with k = 3: \" + str(k_3.score(X_train, y_train)))\n",
    "print(\"k-nearest neighbors testing accuracy with k = 3: \" + str(k_3.score(X_test, y_test)))\n",
    "\n",
    "print(\"k-nearest neighbors training accuracy with k = 5: \" + str(k_5.score(X_train, y_train)))\n",
    "print(\"k-nearest neighbors testing accuracy with k = 5: \" + str(k_5.score(X_test, y_test)))\n",
    "\n",
    "print(\"k-nearest neighbors training accuracy with k = 15: \" + str(k_15.score(X_train, y_train)))\n",
    "print(\"k-nearest neighbors testing accuracy with k = 15: \" + str(k_15.score(X_test, y_test)))\n",
    "\n",
    "print(\"k-nearest neighbors training accuracy with k = 25: \" + str(k_25.score(X_train, y_train)))\n",
    "print(\"k-nearest neighbors testing accuracy with k = 25: \" + str(k_25.score(X_test, y_test)))\n",
    "\n",
    "print(\"logistic regression training accuracy with LASSO penalty, alpha = 1: \" + str(lasso_1.score(X_train, y_train)))\n",
    "print(\"logistic regression testing accuracy with LASSO penalty, alpha = 1: \" + str(lasso_1.score(X_test, y_test)))\n",
    "\n",
    "print(\"logistic regression training accuracy with LASSO penalty, alpha = 10: \" + str(lasso_10.score(X_train, y_train)))\n",
    "print(\"logistic regression testing accuracy with LASSO penalty, alpha = 10: \" + str(lasso_10.score(X_test, y_test)))\n",
    "\n",
    "print(\"logistic regression training accuracy with Ridge penalty, alpha = 1: \" + str(ridge_1.score(X_train, y_train)))\n",
    "print(\"logistic regression testing accuracy with Ridge penalty, alpha = 1: \" + str(ridge_1.score(X_test, y_test)))\n",
    "\n",
    "print(\"logistic regression training accuracy with Ridge penalty, alpha = 10: \" + str(ridge_10.score(X_train, y_train)))\n",
    "print(\"logistic regression testing accuracy with Ridge penalty, alpha = 10: \" + str(ridge_10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In which of your $k$-NN models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: k-NN of 3 and 5 because they overperformed on training relative to testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Broadly speaking, how does the value of $k$ in $k$-NN affect the bias-variance tradeoff? (i.e. As $k$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: as k increases, bias increases so variance decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. If you have a $k$-NN model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Simplifying the model by reducing features\n",
    "        Using a different model\n",
    "        Increase k.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. In which of your logistic regression models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: None because there is no differential between training scores and testing scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Broadly speaking, how does the value of $C$ in logistic regression affect the bias-variance tradeoff? (i.e. As $C$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. For your logistic regression models, play around with the regularization hyperparameter, $C$. As you vary $C$, what happens to the fit and coefficients in the model? What do you think this means in the context of this specific problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. If you have a logistic regression model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Reduce features of the model\n",
    "        Try various regularization methods\n",
    "        Using more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "### 24. Suppose you want to understand which psychological features are most important in determining left-handedness. Would you rather use $k$-NN or logistic regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Logistic Regression because it gives us a straightforward answer to our question of how do these features relate to left-handedness and by how much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Select your logistic regression model that utilized LASSO regularization with $\\alpha = 1$. Interpret the coefficient for `Q1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(lasso_1.coef_[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: as the response increases in value for q1 there is no mor elikelihood that the respondent is left-handed than lower values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. If you have to select one model overall to be your *best* model, which model would you select? Why?\n",
    "- Usually in the \"real world,\" you'll fit many types of models but ultimately need to pick only one! (For example, a client may not understand what it means to have multiple models, or if you're using an algorithm to make a decision, it's probably pretty challenging to use two or more algorithms simultaneously.) It's not always an easy choice, but you'll have to make it soon enough. Pick a model and defend why you picked this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: the logistic regression models were all the same and good for this problem because we are concerned with the relationshio between features and outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Circle back to the three specific and conclusively answerable questions you came up with in Q1. Answer one of these for the professor based on the model you selected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9901889304767827"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(lasso_1.coef_[0][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As someones affinity for guns increases their likelihood of being lefthanded increases by less than 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Looking for more to do? Probably not - you're busy! But if you want to, consider exploring the following. (They could make for a blog post!)\n",
    "- Create a visual plot comparing training and test metrics for various values of $k$ and various regularization schemes in logistic regression.\n",
    "- Rather than just evaluating models based on accuracy, consider using sensitivity, specificity, etc.\n",
    "- In the context of predicting left-handedness, why are unbalanced classes concerning? If you were to re-do this process given those concerns, what changes might you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
